"""
Advanced AI Agents System
Enhanced autonomous agents with deep learning capabilities
PERFORMANCE TARGETS: 95%+ accuracy, <2% false positives, continuous improvement
"""

import asyncio
import logging
import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import sqlite3
import hashlib
import pickle
from pathlib import Path
import time

# Configure enhanced logging for performance tracking
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Performance tracking globals
PERFORMANCE_TARGET_ACCURACY = 95.0
PERFORMANCE_TARGET_FALSE_POSITIVE_RATE = 2.0
PERFORMANCE_TARGET_RESPONSE_TIME = 0.5
CONTINUOUS_IMPROVEMENT_ENABLED = True

class ThreatType(Enum):
    """Types of security threats"""
    MALWARE = "malware"
    PHISHING = "phishing"
    DDOS = "ddos"
    INSIDER_THREAT = "insider_threat"
    DATA_BREACH = "data_breach"
    SMART_CONTRACT_VULNERABILITY = "smart_contract_vulnerability"
    DEFI_EXPLOIT = "defi_exploit"
    SOCIAL_ENGINEERING = "social_engineering"
    ZERO_DAY = "zero_day"
    APT = "apt"  # Advanced Persistent Threat

class AlertSeverity(Enum):
    """Alert severity levels"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4
    EMERGENCY = 5

@dataclass
class ThreatVector:
    """Represents a threat detection vector"""
    vector_id: str
    threat_type: ThreatType
    features: List[float]
    confidence: float
    timestamp: datetime
    source: str
    metadata: Dict[str, Any]

@dataclass
class DetectionResult:
    """Result of threat detection analysis"""
    threat_detected: bool
    threat_type: Optional[ThreatType]
    confidence: float
    severity: AlertSeverity
    features_used: List[str]
    explanation: str
    recommended_actions: List[str]
    timestamp: datetime

class AdvancedThreatDetectionEngine:
    """
    Advanced threat detection using machine learning and pattern recognition
    """
    
    def __init__(self, model_path: str = "models/threat_detection"):
        self.model_path = Path(model_path)
        self.model_path.mkdir(parents=True, exist_ok=True)
        
        # Initialize feature extractors
        self.feature_extractors = {
            'network': self._extract_network_features,
            'behavioral': self._extract_behavioral_features,
            'content': self._extract_content_features,
            'temporal': self._extract_temporal_features,
            'blockchain': self._extract_blockchain_features
        }
        
        # Initialize threat models (simplified for demo)
        self.threat_models = {}
        self.initialize_models()
        
        # Pattern recognition database
        self.pattern_db = self._init_pattern_database()
        
        # Learning metrics
        self.learning_metrics = {
            'patterns_learned': 0,
            'accuracy_improvements': [],
            'false_positive_reduction': [],
            'detection_speed_improvements': []
        }
    
    def initialize_models(self):
        """Initialize machine learning models for different threat types"""
        # In a real implementation, these would be actual ML models
        # For demo purposes, we'll use simplified rule-based systems
        
        self.threat_models = {
            ThreatType.MALWARE: self._create_malware_model(),
            ThreatType.PHISHING: self._create_phishing_model(),
            ThreatType.DDOS: self._create_ddos_model(),
            ThreatType.INSIDER_THREAT: self._create_insider_model(),
            ThreatType.SMART_CONTRACT_VULNERABILITY: self._create_contract_model(),
            ThreatType.DEFI_EXPLOIT: self._create_defi_model()
        }
    
    def _create_malware_model(self) -> Dict[str, Any]:
        """Create malware detection model"""
        return {
            'type': 'ensemble',
            'features': ['file_entropy', 'api_calls', 'network_connections', 'registry_modifications'],
            'thresholds': {'entropy': 7.5, 'suspicious_apis': 5, 'network_score': 0.8},
            'accuracy': 0.94,
            'last_trained': datetime.now()
        }
    
    def _create_phishing_model(self) -> Dict[str, Any]:
        """Create phishing detection model"""
        return {
            'type': 'neural_network',
            'features': ['url_structure', 'content_similarity', 'domain_reputation', 'ssl_certificate'],
            'thresholds': {'similarity_score': 0.85, 'reputation_score': 0.3},
            'accuracy': 0.96,
            'last_trained': datetime.now()
        }
    
    def _create_ddos_model(self) -> Dict[str, Any]:
        """Create DDoS detection model"""
        return {
            'type': 'anomaly_detection',
            'features': ['request_rate', 'source_diversity', 'payload_size', 'response_time'],
            'thresholds': {'rate_threshold': 1000, 'diversity_score': 0.1},
            'accuracy': 0.92,
            'last_trained': datetime.now()
        }
    
    def _create_insider_model(self) -> Dict[str, Any]:
        """Create insider threat detection model with enhanced performance tracking"""
        return {
            'type': 'behavioral_analysis',
            'features': ['access_patterns', 'data_volume', 'time_anomalies', 'privilege_escalation'],
            'thresholds': {'anomaly_score': 0.75, 'risk_score': 0.85},  # Increased for higher accuracy
            'accuracy': 0.92,  # Target higher accuracy
            'performance_target': PERFORMANCE_TARGET_ACCURACY,
            'last_trained': datetime.now(),
            'training_cycles': 0,
            'improvement_rate': 0.0,
            'feature_weights': {'access_patterns': 0.3, 'data_volume': 0.2, 'time_anomalies': 0.25, 'privilege_escalation': 0.25}
        }
    
    def _create_contract_model(self) -> Dict[str, Any]:
        """Create smart contract vulnerability model with performance enhancement"""
        return {
            'type': 'static_analysis',
            'features': ['reentrancy_patterns', 'overflow_checks', 'access_controls', 'randomness_issues'],
            'thresholds': {'vulnerability_score': 0.85, 'critical_score': 0.95},  # Increased thresholds
            'accuracy': 0.95,  # Target higher accuracy
            'performance_target': PERFORMANCE_TARGET_ACCURACY,
            'last_trained': datetime.now(),
            'training_cycles': 0,
            'improvement_rate': 0.0,
            'confidence_calibration': {'scale_factor': 0.9, 'min_threshold': 0.7}
        }
    
    def _create_defi_model(self) -> Dict[str, Any]:
        """Create DeFi exploit detection model with enhanced accuracy"""
        return {
            'type': 'transaction_analysis',
            'features': ['flash_loan_patterns', 'arbitrage_signals', 'liquidity_manipulation', 'price_impact'],
            'thresholds': {'exploit_probability': 0.8, 'value_at_risk': 1000000},  # Higher threshold
            'accuracy': 0.93,  # Target higher accuracy
            'performance_target': PERFORMANCE_TARGET_ACCURACY,
            'last_trained': datetime.now(),
            'training_cycles': 0,
            'improvement_rate': 0.0,
            'adaptive_learning': True
        }
    
    def _init_pattern_database(self) -> sqlite3.Connection:
        """Initialize enhanced pattern recognition database with performance tracking"""
        db_path = self.model_path / "patterns.db"
        conn = sqlite3.connect(str(db_path))
        
        # Enhanced patterns table with performance metrics
        conn.execute('''
            CREATE TABLE IF NOT EXISTS threat_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_hash TEXT UNIQUE,
                threat_type TEXT,
                features TEXT,
                confidence REAL,
                occurrences INTEGER DEFAULT 1,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                accuracy REAL,
                false_positives INTEGER DEFAULT 0,
                performance_score REAL DEFAULT 0.0,
                training_round INTEGER DEFAULT 0,
                improvement_rate REAL DEFAULT 0.0
            )
        ''')
        
        # Performance tracking table
        conn.execute('''
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP,
                metric_name TEXT,
                metric_value REAL,
                target_value REAL,
                model_type TEXT,
                session_id TEXT
            )
        ''')
        
        # Real-time alerts table
        conn.execute('''
            CREATE TABLE IF NOT EXISTS performance_alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP,
                alert_level TEXT,
                metric_name TEXT,
                current_value REAL,
                threshold_value REAL,
                auto_correction_applied BOOLEAN DEFAULT FALSE
            )
        ''')
        
        conn.execute('''
            CREATE TABLE IF NOT EXISTS learning_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP,
                event_type TEXT,
                description TEXT,
                metrics TEXT,
                improvement_score REAL
            )
        ''')
        
        conn.commit()
        return conn
    
    def _extract_network_features(self, data: Dict[str, Any]) -> List[float]:
        """Extract network-based features"""
        features = []
        
        # Connection patterns
        conn_count = data.get('connection_count', 0)
        features.append(min(conn_count / 1000.0, 1.0))  # Normalize to 0-1
        
        # Protocol distribution
        tcp_ratio = data.get('tcp_ratio', 0.5)
        features.append(tcp_ratio)
        
        # Port usage patterns
        common_ports = data.get('common_ports_ratio', 0.8)
        features.append(common_ports)
        
        # Geographic diversity
        geo_diversity = data.get('geographic_diversity', 0.3)
        features.append(geo_diversity)
        
        # Bandwidth usage
        bandwidth = data.get('bandwidth_usage', 0)
        features.append(min(bandwidth / 1000000.0, 1.0))  # Normalize MB
        
        return features
    
    def _extract_behavioral_features(self, data: Dict[str, Any]) -> List[float]:
        """Extract behavioral features"""
        features = []
        
        # User activity patterns
        activity_score = data.get('activity_anomaly_score', 0.0)
        features.append(activity_score)
        
        # Access patterns
        access_pattern_score = data.get('access_pattern_score', 0.0)
        features.append(access_pattern_score)
        
        # Time-based anomalies
        time_anomaly = data.get('time_anomaly_score', 0.0)
        features.append(time_anomaly)
        
        # Privilege usage
        privilege_score = data.get('privilege_usage_score', 0.0)
        features.append(privilege_score)
        
        # Data access volume
        data_volume = data.get('data_access_volume', 0)
        features.append(min(data_volume / 10000.0, 1.0))  # Normalize
        
        return features
    
    def _extract_content_features(self, data: Dict[str, Any]) -> List[float]:
        """Extract content-based features"""
        features = []
        
        # Entropy analysis
        entropy = data.get('content_entropy', 0.0)
        features.append(entropy / 8.0)  # Max entropy is 8 bits
        
        # Similarity scores
        similarity = data.get('content_similarity', 0.0)
        features.append(similarity)
        
        # Language patterns
        language_score = data.get('language_anomaly_score', 0.0)
        features.append(language_score)
        
        # Metadata consistency
        metadata_score = data.get('metadata_consistency', 1.0)
        features.append(metadata_score)
        
        # Compression ratio
        compression_ratio = data.get('compression_ratio', 0.5)
        features.append(compression_ratio)
        
        return features
    
    def _extract_temporal_features(self, data: Dict[str, Any]) -> List[float]:
        """Extract temporal features"""
        features = []
        
        # Frequency analysis
        frequency = data.get('event_frequency', 0)
        features.append(min(frequency / 100.0, 1.0))  # Normalize
        
        # Timing patterns
        timing_regularity = data.get('timing_regularity', 0.5)
        features.append(timing_regularity)
        
        # Burst detection
        burst_score = data.get('burst_score', 0.0)
        features.append(burst_score)
        
        # Time-of-day patterns
        tod_anomaly = data.get('time_of_day_anomaly', 0.0)
        features.append(tod_anomaly)
        
        # Duration analysis
        duration_score = data.get('duration_anomaly_score', 0.0)
        features.append(duration_score)
        
        return features
    
    def _extract_blockchain_features(self, data: Dict[str, Any]) -> List[float]:
        """Extract blockchain-specific features"""
        features = []
        
        # Transaction patterns
        tx_volume = data.get('transaction_volume', 0)
        features.append(min(tx_volume / 1000000.0, 1.0))  # Normalize
        
        # Gas usage patterns
        gas_efficiency = data.get('gas_efficiency', 0.5)
        features.append(gas_efficiency)
        
        # Contract interaction patterns
        contract_calls = data.get('contract_call_frequency', 0)
        features.append(min(contract_calls / 100.0, 1.0))
        
        # Value transfer patterns
        value_anomaly = data.get('value_transfer_anomaly', 0.0)
        features.append(value_anomaly)
        
        # MEV detection signals
        mev_score = data.get('mev_detection_score', 0.0)
        features.append(mev_score)
        
        return features
    
    async def analyze_threat_vector(self, vector: ThreatVector) -> DetectionResult:
        """Analyze a threat vector using advanced ML techniques"""
        
        # Extract all feature types
        all_features = []
        features_used = []
        
        for feature_type, extractor in self.feature_extractors.items():
            if feature_type in vector.metadata:
                extracted_features = extractor(vector.metadata[feature_type])
                all_features.extend(extracted_features)
                features_used.append(feature_type)
        
        # Combine with vector features
        combined_features = vector.features + all_features
        
        # Run through threat models with improved selection logic
        detection_results = []
        
        for threat_type, model in self.threat_models.items():
            confidence = await self._evaluate_model(model, combined_features)
            
            # Apply feature-type filtering to improve accuracy
            relevant_features = self._get_relevant_features_for_threat(threat_type, features_used)
            
            # Reduce confidence if irrelevant features are primary
            if not relevant_features:
                confidence *= 0.3  # Heavily penalize irrelevant feature combinations
            elif len(relevant_features) == 1 and len(features_used) > 2:
                confidence *= 0.6  # Penalize single feature matches with multiple inputs
            
            # Apply minimum confidence thresholds per threat type
            min_confidence = self._get_min_confidence_threshold(threat_type)
            if confidence < min_confidence:
                continue
                
            if confidence > 0.5:  # Increased base threshold
                detection_results.append((threat_type, confidence))
        
        # Determine final result with improved logic
        if detection_results:
            # Sort by confidence and take highest, but apply additional filtering
            detection_results.sort(key=lambda x: x[1], reverse=True)
            best_threat, best_confidence = detection_results[0]
            
            # Additional validation: check if confidence is significantly higher than others
            if len(detection_results) > 1:
                second_best_confidence = detection_results[1][1]
                confidence_gap = best_confidence - second_best_confidence
                if confidence_gap < 0.2:  # If too close, reduce confidence
                    best_confidence *= 0.8
            
            # Final confidence check
            if best_confidence < 0.6:  # Require high confidence for final detection
                return DetectionResult(
                    threat_detected=False,
                    threat_type=None,
                    confidence=0.0,
                    severity=AlertSeverity.LOW,
                    features_used=features_used,
                    explanation="Insufficient confidence for threat classification",
                    recommended_actions=["Continue monitoring"],
                    timestamp=datetime.now()
                )
            
            # Performance tracking for detection
            start_time = time.time()
            
            # Determine severity
            severity = self._calculate_severity(best_threat, best_confidence)
            
            # Generate explanation
            explanation = self._generate_explanation(best_threat, best_confidence, features_used)
            
            # Generate recommendations
            recommendations = self._generate_recommendations(best_threat, severity)
            
            # Track response time
            response_time = time.time() - start_time
            
            result = DetectionResult(
                threat_detected=True,
                threat_type=best_threat,
                confidence=best_confidence,
                severity=severity,
                features_used=features_used,
                explanation=explanation,
                recommended_actions=recommendations,
                timestamp=datetime.now()
            )
            
            # Performance monitoring and auto-improvement
            await self._track_detection_performance(result, response_time)
            
        else:
            result = DetectionResult(
                threat_detected=False,
                threat_type=None,
                confidence=0.0,
                severity=AlertSeverity.LOW,
                features_used=features_used,
                explanation="No significant threats detected in analysis",
                recommended_actions=["Continue monitoring"],
                timestamp=datetime.now()
            )
        
        # Store pattern for learning
        await self._store_detection_pattern(vector, result)
        
        # Check if continuous improvement is needed
        if CONTINUOUS_IMPROVEMENT_ENABLED:
            await self._check_and_apply_improvements(result)
        
        return result
    
    async def _track_detection_performance(self, result: DetectionResult, response_time: float):
        """Track detection performance for continuous improvement"""
        try:
            # Check response time performance
            if response_time > PERFORMANCE_TARGET_RESPONSE_TIME:
                logger.warning(f"Response time {response_time:.3f}s exceeds target {PERFORMANCE_TARGET_RESPONSE_TIME}s")
                await self._optimize_response_time()
            
            # Track confidence accuracy
            if result.threat_detected and result.confidence < 0.7:
                logger.info(f"Low confidence detection: {result.confidence:.2f} for {result.threat_type.value}")
                await self._calibrate_confidence_for_threat_type(result.threat_type)
            
            # Log performance metrics
            await self._log_performance_metric("response_time", response_time, PERFORMANCE_TARGET_RESPONSE_TIME)
            await self._log_performance_metric("detection_confidence", result.confidence, 0.8)
            
        except Exception as e:
            logger.error(f"Error tracking performance: {e}")
    
    async def _optimize_response_time(self):
        """Optimize response time through model tuning"""
        logger.info("ðŸš€ Applying response time optimization...")
        
        # Reduce feature computation complexity
        for threat_type, model in self.threat_models.items():
            if 'feature_weights' in model:
                # Prioritize most important features
                top_features = sorted(model['feature_weights'].items(), key=lambda x: x[1], reverse=True)[:3]
                model['optimized_features'] = [f[0] for f in top_features]
    
    async def _calibrate_confidence_for_threat_type(self, threat_type: ThreatType):
        """Calibrate confidence scoring for specific threat type"""
        if threat_type in self.threat_models:
            model = self.threat_models[threat_type]
            if 'confidence_calibration' in model:
                # Increase confidence scale factor slightly
                model['confidence_calibration']['scale_factor'] = min(1.0, 
                    model['confidence_calibration']['scale_factor'] + 0.02)
                logger.info(f"ðŸŽ¯ Calibrated confidence for {threat_type.value}")
    
    async def _log_performance_metric(self, metric_name: str, value: float, target: float):
        """Log performance metric to database"""
        try:
            conn = sqlite3.connect(str(self.model_path / "patterns.db"))
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO performance_metrics 
                (timestamp, metric_name, metric_value, target_value, model_type, session_id)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                datetime.now().isoformat(),
                metric_name,
                value,
                target,
                'ensemble',
                f"session_{datetime.now().strftime('%Y%m%d_%H')}"
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Error logging performance metric: {e}")
    
    async def _check_and_apply_improvements(self, result: DetectionResult):
        """Check if improvements are needed and apply them automatically"""
        try:
            # Check for potential false positive (low confidence threat detection)
            if result.threat_detected and result.confidence < 0.6:
                await self._apply_false_positive_reduction(result.threat_type)
            
            # Check for potential improvement opportunities
            if result.threat_detected and result.confidence > 0.95:
                await self._reinforce_successful_pattern(result)
            
        except Exception as e:
            logger.error(f"Error in continuous improvement: {e}")
    
    async def _apply_false_positive_reduction(self, threat_type: ThreatType):
        """Apply false positive reduction for specific threat type"""
        if threat_type in self.threat_models:
            model = self.threat_models[threat_type]
            
            # Increase thresholds slightly to reduce false positives
            for threshold_name in model.get('thresholds', {}):
                current_threshold = model['thresholds'][threshold_name]
                model['thresholds'][threshold_name] = min(0.95, current_threshold + 0.02)
            
            logger.info(f"ðŸ”§ Applied false positive reduction for {threat_type.value}")
    
    async def _reinforce_successful_pattern(self, result: DetectionResult):
        """Reinforce successful detection patterns"""
        try:
            # Increase accuracy tracking for this threat type
            if result.threat_type in self.threat_models:
                model = self.threat_models[result.threat_type]
                model['training_cycles'] = model.get('training_cycles', 0) + 1
                
                # Calculate improvement rate
                old_accuracy = model.get('accuracy', 0.0)
                model['accuracy'] = min(0.99, old_accuracy + 0.001)  # Slight improvement
                model['improvement_rate'] = model['accuracy'] - old_accuracy
                
                logger.info(f"âœ… Reinforced pattern for {result.threat_type.value} (accuracy: {model['accuracy']:.3f})")
                
        except Exception as e:
            logger.error(f"Error reinforcing pattern: {e}")

    async def _evaluate_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate a specific threat model against features with performance optimization"""
        
        model_type = model['type']
        
        if model_type == 'ensemble':
            return await self._evaluate_ensemble_model(model, features)
        elif model_type == 'neural_network':
            return await self._evaluate_neural_model(model, features)
        elif model_type == 'anomaly_detection':
            return await self._evaluate_anomaly_model(model, features)
        elif model_type == 'behavioral_analysis':
            return await self._evaluate_behavioral_model(model, features)
        elif model_type == 'static_analysis':
            return await self._evaluate_static_model(model, features)
        elif model_type == 'transaction_analysis':
            return await self._evaluate_transaction_model(model, features)
        else:
            return 0.0
    
    async def _evaluate_ensemble_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate ensemble model with improved discrimination"""
        if len(features) < 4:
            return 0.0
        
        # Apply model-specific thresholds
        thresholds = model.get('thresholds', {})
        entropy_threshold = thresholds.get('entropy', 8.0)  # Higher threshold
        network_threshold = thresholds.get('network_score', 0.85)  # Higher threshold
        
        # Improved ensemble scoring with stricter requirements
        scores = []
        
        # Feature-based scoring with higher thresholds
        if len(features) > 0:
            entropy_score = features[0] if features[0] > 0.85 else 0.0  # Increased threshold
            scores.append(entropy_score)
        
        if len(features) > 1:
            network_score = features[1] if features[1] > 0.8 else 0.0  # Increased threshold
            scores.append(network_score)
        
        if len(features) > 2:
            behavior_score = features[2] if features[2] > 0.75 else 0.0  # Increased threshold
            scores.append(behavior_score)
        
        # Require multiple indicators for high confidence
        non_zero_scores = [s for s in scores if s > 0]
        if len(non_zero_scores) < 2:  # Need at least 2 indicators
            return 0.0
        
        return np.mean(non_zero_scores) if non_zero_scores else 0.0
    
    async def _evaluate_neural_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate neural network model with better thresholds"""
        if len(features) < 3:
            return 0.0
        
        # Apply model-specific thresholds
        thresholds = model.get('thresholds', {})
        similarity_threshold = thresholds.get('similarity_score', 0.90)
        
        # Improved neural network simulation with stricter requirements
        weights = [0.4, 0.3, 0.2, 0.1][:len(features)]
        weighted_sum = sum(w * f for w, f in zip(weights, features))
        
        # Apply minimum threshold before sigmoid
        if weighted_sum < 0.6:  # Require significant weighted score
            return 0.0
        
        # Sigmoid activation with adjusted range
        confidence = 1 / (1 + np.exp(-(weighted_sum - 0.5) * 6))  # Shifted and scaled
        
        # Additional filtering for very low confidence
        if confidence < 0.7:
            return 0.0
            
        return confidence
    
    async def _evaluate_anomaly_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate anomaly detection model with improved thresholds"""
        if not features:
            return 0.0
        
        # Calculate anomaly score based on deviation from normal with higher thresholds
        normal_baseline = 0.5
        max_deviation = max(abs(f - normal_baseline) for f in features)
        
        # Apply model-specific thresholds to reduce false positives
        thresholds = model.get('thresholds', {})
        rate_threshold = thresholds.get('rate_threshold', 2000)  # Updated threshold
        diversity_threshold = thresholds.get('diversity_score', 0.05)  # Updated threshold
        
        # Only trigger on very high deviations for DDoS-like patterns
        if max_deviation < 0.4:  # Require significant deviation
            return 0.0
        
        # Additional checks for legitimate vs malicious patterns
        avg_feature = np.mean(features)
        if avg_feature < 0.3:  # Low average suggests benign activity
            return 0.0
        
        # Convert deviation to confidence score with dampening
        confidence = min(max_deviation * 1.5, 1.0)  # Reduced multiplier
        
        # Apply additional filtering for very low scores
        if confidence < 0.6:  # Require high confidence for detection
            return 0.0
            
        return confidence
    
    def _get_relevant_features_for_threat(self, threat_type: ThreatType, features_used: List[str]) -> List[str]:
        """Get relevant features for a specific threat type"""
        relevance_map = {
            ThreatType.MALWARE: ['network', 'behavioral', 'content'],
            ThreatType.PHISHING: ['content', 'network'],
            ThreatType.DDOS: ['network', 'temporal'],
            ThreatType.INSIDER_THREAT: ['behavioral', 'temporal'],
            ThreatType.SMART_CONTRACT_VULNERABILITY: ['blockchain', 'content'],
            ThreatType.DEFI_EXPLOIT: ['blockchain', 'temporal']
        }
        
        relevant = relevance_map.get(threat_type, [])
        return [f for f in features_used if f in relevant]
    
    def _get_min_confidence_threshold(self, threat_type: ThreatType) -> float:
        """Get minimum confidence threshold for threat type"""
        thresholds = {
            ThreatType.MALWARE: 0.75,
            ThreatType.PHISHING: 0.80,
            ThreatType.DDOS: 0.85,  # Higher threshold for DDoS
            ThreatType.INSIDER_THREAT: 0.70,
            ThreatType.SMART_CONTRACT_VULNERABILITY: 0.80,
            ThreatType.DEFI_EXPLOIT: 0.75
        }
        
        return thresholds.get(threat_type, 0.70)
    
    async def _evaluate_behavioral_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate behavioral analysis model"""
        if len(features) < 2:
            return 0.0
        
        # Behavioral scoring based on pattern deviation
        pattern_scores = []
        
        for i, feature in enumerate(features[:4]):  # Use first 4 features
            if feature > 0.7:  # High anomaly threshold
                pattern_scores.append(feature)
        
        return np.mean(pattern_scores) if pattern_scores else 0.0
    
    async def _evaluate_static_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate static analysis model"""
        if not features:
            return 0.0
        
        # Static analysis scoring
        vulnerability_indicators = [f for f in features if f > 0.6]
        
        if not vulnerability_indicators:
            return 0.0
        
        # Weight critical indicators higher
        critical_score = max(vulnerability_indicators)
        return critical_score
    
    async def _evaluate_transaction_model(self, model: Dict[str, Any], features: List[float]) -> float:
        """Evaluate transaction analysis model"""
        if len(features) < 3:
            return 0.0
        
        # Transaction pattern analysis
        suspicious_patterns = 0
        
        # Check for flash loan patterns
        if len(features) > 0 and features[0] > 0.8:
            suspicious_patterns += 1
        
        # Check for MEV patterns
        if len(features) > 4 and features[4] > 0.7:
            suspicious_patterns += 1
        
        # Check for liquidity manipulation
        if len(features) > 2 and features[2] > 0.6:
            suspicious_patterns += 1
        
        confidence = min(suspicious_patterns / 3.0, 1.0)
        return confidence
    
    def _calculate_severity(self, threat_type: ThreatType, confidence: float) -> AlertSeverity:
        """Calculate alert severity based on threat type and confidence"""
        
        # Base severity by threat type
        base_severity = {
            ThreatType.MALWARE: AlertSeverity.HIGH,
            ThreatType.PHISHING: AlertSeverity.MEDIUM,
            ThreatType.DDOS: AlertSeverity.HIGH,
            ThreatType.INSIDER_THREAT: AlertSeverity.CRITICAL,
            ThreatType.DATA_BREACH: AlertSeverity.CRITICAL,
            ThreatType.SMART_CONTRACT_VULNERABILITY: AlertSeverity.HIGH,
            ThreatType.DEFI_EXPLOIT: AlertSeverity.CRITICAL,
            ThreatType.SOCIAL_ENGINEERING: AlertSeverity.MEDIUM,
            ThreatType.ZERO_DAY: AlertSeverity.EMERGENCY,
            ThreatType.APT: AlertSeverity.CRITICAL
        }.get(threat_type, AlertSeverity.MEDIUM)
        
        # Adjust based on confidence
        if confidence > 0.9:
            # Very high confidence - escalate severity
            if base_severity.value < AlertSeverity.CRITICAL.value:
                return AlertSeverity(base_severity.value + 1)
        elif confidence < 0.6:
            # Lower confidence - reduce severity
            if base_severity.value > AlertSeverity.LOW.value:
                return AlertSeverity(base_severity.value - 1)
        
        return base_severity
    
    def _generate_explanation(self, threat_type: ThreatType, confidence: float, features_used: List[str]) -> str:
        """Generate human-readable explanation of the detection"""
        
        explanations = {
            ThreatType.MALWARE: f"Malware detected with {confidence:.1%} confidence based on suspicious file characteristics and behavior patterns.",
            ThreatType.PHISHING: f"Phishing attempt identified with {confidence:.1%} confidence through URL analysis and content examination.",
            ThreatType.DDOS: f"DDoS attack detected with {confidence:.1%} confidence based on traffic volume and pattern analysis.",
            ThreatType.INSIDER_THREAT: f"Insider threat detected with {confidence:.1%} confidence through behavioral anomaly analysis.",
            ThreatType.SMART_CONTRACT_VULNERABILITY: f"Smart contract vulnerability found with {confidence:.1%} confidence via static code analysis.",
            ThreatType.DEFI_EXPLOIT: f"DeFi exploit detected with {confidence:.1%} confidence through transaction pattern analysis."
        }
        
        base_explanation = explanations.get(threat_type, f"Threat detected with {confidence:.1%} confidence.")
        feature_info = f" Analysis used: {', '.join(features_used)}."
        
        return base_explanation + feature_info
    
    def _generate_recommendations(self, threat_type: ThreatType, severity: AlertSeverity) -> List[str]:
        """Generate recommended actions based on threat type and severity"""
        
        recommendations = {
            ThreatType.MALWARE: [
                "Isolate affected systems immediately",
                "Run full antivirus scan",
                "Check for lateral movement",
                "Update security signatures"
            ],
            ThreatType.PHISHING: [
                "Block malicious URLs",
                "Notify affected users",
                "Update email filters",
                "Conduct security awareness training"
            ],
            ThreatType.DDOS: [
                "Activate DDoS mitigation",
                "Scale up infrastructure",
                "Block attack sources",
                "Monitor bandwidth usage"
            ],
            ThreatType.INSIDER_THREAT: [
                "Review user permissions",
                "Monitor user activity closely",
                "Conduct security interview",
                "Implement additional access controls"
            ],
            ThreatType.SMART_CONTRACT_VULNERABILITY: [
                "Pause contract operations",
                "Conduct emergency audit",
                "Prepare security patch",
                "Notify stakeholders"
            ],
            ThreatType.DEFI_EXPLOIT: [
                "Pause affected pools",
                "Investigate transaction flow",
                "Alert community",
                "Implement emergency controls"
            ]
        }
        
        base_recommendations = recommendations.get(threat_type, ["Investigate further", "Monitor closely"])
        
        # Add severity-specific recommendations
        if severity in [AlertSeverity.CRITICAL, AlertSeverity.EMERGENCY]:
            base_recommendations.insert(0, "Activate incident response team")
            base_recommendations.append("Prepare public disclosure")
        
        return base_recommendations
    
    async def _store_detection_pattern(self, vector: ThreatVector, result: DetectionResult):
        """Store detection pattern for continuous learning"""
        
        # Create pattern hash
        pattern_data = {
            'features': vector.features,
            'metadata_keys': list(vector.metadata.keys()),
            'threat_type': result.threat_type.value if result.threat_type else None,
            'confidence': result.confidence
        }
        
        pattern_hash = hashlib.sha256(json.dumps(pattern_data, sort_keys=True).encode()).hexdigest()
        
        # Store in database
        try:
            cursor = self.pattern_db.cursor()
            
            # Check if pattern exists
            cursor.execute("SELECT id, occurrences FROM threat_patterns WHERE pattern_hash = ?", (pattern_hash,))
            existing = cursor.fetchone()
            
            if existing:
                # Update existing pattern
                cursor.execute(
                    "UPDATE threat_patterns SET occurrences = occurrences + 1, last_seen = ? WHERE pattern_hash = ?",
                    (datetime.now(), pattern_hash)
                )
            else:
                # Insert new pattern
                cursor.execute(
                    '''INSERT INTO threat_patterns 
                       (pattern_hash, threat_type, features, confidence, first_seen, last_seen, accuracy)
                       VALUES (?, ?, ?, ?, ?, ?, ?)''',
                    (pattern_hash, 
                     result.threat_type.value if result.threat_type else 'none',
                     json.dumps(vector.features),
                     result.confidence,
                     datetime.now(),
                     datetime.now(),
                     0.85)  # Initial accuracy estimate
                )
                
                self.learning_metrics['patterns_learned'] += 1
            
            self.pattern_db.commit()
            
        except Exception as e:
            logger.error(f"Error storing detection pattern: {e}")
    
    async def continuous_learning_cycle(self):
        """Continuous learning and model improvement cycle"""
        
        while True:
            try:
                # Analyze recent patterns
                await self._analyze_pattern_effectiveness()
                
                # Update model thresholds
                await self._optimize_model_parameters()
                
                # Generate learning report
                await self._generate_learning_report()
                
                # Sleep for learning cycle interval
                await asyncio.sleep(3600)  # 1 hour learning cycles
                
            except Exception as e:
                logger.error(f"Error in continuous learning cycle: {e}")
                await asyncio.sleep(300)  # 5 minute retry
    
    async def _analyze_pattern_effectiveness(self):
        """Analyze effectiveness of learned patterns"""
        
        cursor = self.pattern_db.cursor()
        
        # Get patterns from last 24 hours
        yesterday = datetime.now() - timedelta(hours=24)
        cursor.execute(
            "SELECT * FROM threat_patterns WHERE last_seen > ? ORDER BY occurrences DESC",
            (yesterday,)
        )
        
        patterns = cursor.fetchall()
        
        if patterns:
            # Calculate pattern effectiveness metrics
            total_patterns = len(patterns)
            high_confidence_patterns = len([p for p in patterns if p[4] > 0.8])  # confidence > 0.8
            
            effectiveness_score = high_confidence_patterns / total_patterns if total_patterns > 0 else 0
            
            # Store learning metrics
            learning_event = {
                'timestamp': datetime.now(),
                'event_type': 'pattern_analysis',
                'description': f'Analyzed {total_patterns} patterns, {effectiveness_score:.2%} high confidence',
                'metrics': json.dumps({
                    'total_patterns': total_patterns,
                    'high_confidence_patterns': high_confidence_patterns,
                    'effectiveness_score': effectiveness_score
                }),
                'improvement_score': effectiveness_score
            }
            
            cursor.execute(
                '''INSERT INTO learning_history 
                   (timestamp, event_type, description, metrics, improvement_score)
                   VALUES (?, ?, ?, ?, ?)''',
                (learning_event['timestamp'], learning_event['event_type'],
                 learning_event['description'], learning_event['metrics'],
                 learning_event['improvement_score'])
            )
            
            self.pattern_db.commit()
            
            logger.info(f"Pattern analysis complete: {effectiveness_score:.2%} effectiveness")
    
    async def _optimize_model_parameters(self):
        """Optimize model parameters based on learning"""
        
        # Get recent accuracy data
        cursor = self.pattern_db.cursor()
        cursor.execute(
            "SELECT threat_type, AVG(accuracy) as avg_accuracy FROM threat_patterns GROUP BY threat_type"
        )
        
        accuracy_data = cursor.fetchall()
        
        for threat_type_str, avg_accuracy in accuracy_data:
            if threat_type_str != 'none':
                try:
                    threat_type = ThreatType(threat_type_str)
                    
                    if threat_type in self.threat_models:
                        model = self.threat_models[threat_type]
                        current_accuracy = model['accuracy']
                        
                        # Adjust thresholds based on performance
                        if avg_accuracy > current_accuracy:
                            # Improve model accuracy
                            model['accuracy'] = min(avg_accuracy * 1.02, 0.99)  # Incremental improvement
                            
                            # Adjust thresholds to be more sensitive
                            for key, value in model['thresholds'].items():
                                if isinstance(value, float) and value > 0.1:
                                    model['thresholds'][key] = value * 0.98
                            
                            logger.info(f"Optimized {threat_type.value} model: accuracy {model['accuracy']:.3f}")
                        
                        model['last_trained'] = datetime.now()
                
                except ValueError:
                    continue
    
    async def _generate_learning_report(self):
        """Generate comprehensive learning report"""
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'learning_metrics': self.learning_metrics.copy(),
            'model_performance': {},
            'pattern_statistics': {}
        }
        
        # Model performance
        for threat_type, model in self.threat_models.items():
            report['model_performance'][threat_type.value] = {
                'accuracy': model['accuracy'],
                'last_trained': model['last_trained'].isoformat(),
                'thresholds': model['thresholds']
            }
        
        # Pattern statistics
        cursor = self.pattern_db.cursor()
        cursor.execute("SELECT COUNT(*) FROM threat_patterns")
        total_patterns = cursor.fetchone()[0]
        
        cursor.execute("SELECT threat_type, COUNT(*) FROM threat_patterns GROUP BY threat_type")
        pattern_counts = dict(cursor.fetchall())
        
        report['pattern_statistics'] = {
            'total_patterns': total_patterns,
            'patterns_by_type': pattern_counts
        }
        
        # Save report
        report_path = self.model_path / f"learning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"Learning report generated: {report_path}")
        
        return report
    
    def get_model_status(self) -> Dict[str, Any]:
        """Get current status of all models"""
        
        status = {
            'timestamp': datetime.now().isoformat(),
            'models': {},
            'learning_metrics': self.learning_metrics,
            'database_stats': {}
        }
        
        # Model statuses
        for threat_type, model in self.threat_models.items():
            status['models'][threat_type.value] = {
                'type': model['type'],
                'accuracy': model['accuracy'],
                'last_trained': model['last_trained'].isoformat(),
                'feature_count': len(model['features'])
            }
        
        # Database statistics
        cursor = self.pattern_db.cursor()
        cursor.execute("SELECT COUNT(*) FROM threat_patterns")
        pattern_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM learning_history")
        learning_events = cursor.fetchone()[0]
        
        status['database_stats'] = {
            'total_patterns': pattern_count,
            'learning_events': learning_events
        }
        
        return status


class AdvancedAIAgentManager:
    """
    Manager for advanced AI agents with deep learning capabilities
    """
    
    def __init__(self):
        self.detection_engine = AdvancedThreatDetectionEngine()
        self.agents = {}
        self.communication_hub = {}
        self.learning_active = False
    
    async def initialize(self):
        """Initialize the advanced AI agent system"""
        
        logger.info("Initializing Advanced AI Agent System...")
        
        # Start continuous learning
        self.learning_active = True
        asyncio.create_task(self.detection_engine.continuous_learning_cycle())
        
        logger.info("Advanced AI Agent System initialized successfully")
    
    async def process_threat_data(self, data: Dict[str, Any]) -> DetectionResult:
        """Process threat data through advanced AI system"""
        
        # Create threat vector
        vector = ThreatVector(
            vector_id=data.get('id', hashlib.sha256(str(data).encode()).hexdigest()[:16]),
            threat_type=ThreatType(data.get('threat_type', 'malware')),
            features=data.get('features', []),
            confidence=data.get('initial_confidence', 0.5),
            timestamp=datetime.now(),
            source=data.get('source', 'unknown'),
            metadata=data.get('metadata', {})
        )
        
        # Analyze through detection engine
        result = await self.detection_engine.analyze_threat_vector(vector)
        
        return result
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        
        return {
            'learning_active': self.learning_active,
            'detection_engine': self.detection_engine.get_model_status(),
            'timestamp': datetime.now().isoformat()
        }


# Demo and testing
async def demo_advanced_ai_agents():
    """Demonstrate advanced AI agents capabilities"""
    
    print("ðŸ¤– ADVANCED AI AGENTS DEMONSTRATION")
    print("=" * 50)
    
    # Initialize system
    manager = AdvancedAIAgentManager()
    await manager.initialize()
    
    # Test cases
    test_cases = [
        {
            'id': 'test_001',
            'threat_type': 'malware',
            'features': [0.9, 0.8, 0.7, 0.6],
            'metadata': {
                'network': {
                    'connection_count': 1500,
                    'tcp_ratio': 0.9,
                    'common_ports_ratio': 0.2,
                    'geographic_diversity': 0.8,
                    'bandwidth_usage': 5000000
                },
                'behavioral': {
                    'activity_anomaly_score': 0.85,
                    'access_pattern_score': 0.9,
                    'time_anomaly_score': 0.7,
                    'privilege_usage_score': 0.8,
                    'data_access_volume': 15000
                }
            }
        },
        {
            'id': 'test_002',
            'threat_type': 'phishing',
            'features': [0.95, 0.3, 0.8],
            'metadata': {
                'content': {
                    'content_entropy': 6.5,
                    'content_similarity': 0.92,
                    'language_anomaly_score': 0.7,
                    'metadata_consistency': 0.3,
                    'compression_ratio': 0.8
                }
            }
        },
        {
            'id': 'test_003',
            'threat_type': 'defi_exploit',
            'features': [0.8, 0.9, 0.85],
            'metadata': {
                'blockchain': {
                    'transaction_volume': 2000000,
                    'gas_efficiency': 0.3,
                    'contract_call_frequency': 150,
                    'value_transfer_anomaly': 0.9,
                    'mev_detection_score': 0.85
                }
            }
        }
    ]
    
    # Process test cases
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nðŸ” Test Case {i}: {test_case['threat_type'].upper()}")
        print("-" * 30)
        
        result = await manager.process_threat_data(test_case)
        
        print(f"Threat Detected: {result.threat_detected}")
        if result.threat_detected:
            print(f"Threat Type: {result.threat_type.value}")
            print(f"Confidence: {result.confidence:.2%}")
            print(f"Severity: {result.severity.name}")
            print(f"Explanation: {result.explanation}")
            print(f"Recommendations: {', '.join(result.recommended_actions[:2])}...")
    
    # Show system status
    print(f"\nðŸ“Š SYSTEM STATUS")
    print("-" * 30)
    status = manager.get_system_status()
    print(f"Learning Active: {status['learning_active']}")
    print(f"Models Loaded: {len(status['detection_engine']['models'])}")
    print(f"Patterns Learned: {status['detection_engine']['learning_metrics']['patterns_learned']}")
    
    print(f"\nâœ… Advanced AI Agents demonstration complete!")


if __name__ == "__main__":
    asyncio.run(demo_advanced_ai_agents())